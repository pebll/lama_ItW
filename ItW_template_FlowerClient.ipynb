{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqKvlWGyWr5p"
      },
      "source": [
        "# Project Lama Into the Wild:Federated Learning\n",
        "<b>Group Number: 13</b><br>\n",
        "<b>Name Group Member 1: Léo Brucker</b><br>\n",
        "<b>u-Kürzel Group Member 1: uhugu</b><br>\n",
        "<b>Name Group Member 2: Cyril Rudolph</b><br>\n",
        "<b>u-Kürzel Group Member 2: udjvh</b>\n",
        "\n",
        "This file is a Template for creating a new scenario for Testing.\n",
        "\n",
        "Just change the parameters, run the simulation, the output and paramaters will\n",
        "automatically be saved in an excel-sheet (you will have to change the location\n",
        "and create the excel-file before it works). Next step would be to automate the\n",
        "Param Optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms1DURr0XCJB"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaWS5etVZWzx"
      },
      "source": [
        "## Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfmSAOZm1nfw"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision flwr_datasets\n",
        "!pip install --upgrade flwr jax\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tIhSDp51nfz"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUNufHvi1nfz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import EMNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "import copy\n",
        "from torch.utils.data import Subset\n",
        "import openpyxl\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, Tuple\n",
        "from flwr.common import NDArrays, Scalar\n",
        "from collections import Counter\n",
        "\n",
        "import flwr as fl\n",
        "from flwr_datasets import FederatedDataset\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")\n",
        "\n",
        "# Initial SetUp ofr Google Drive Sign-In\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZNDFofYdy2A"
      },
      "source": [
        "# Parameters\n",
        "Change following parameters to create your own simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leMAdkTueDKH"
      },
      "outputs": [],
      "source": [
        "EMNIST_SPLITS = {\n",
        "    \"balanced\": 47,\n",
        "    \"bymerge\": 47,\n",
        "    \"byclass\": 62,\n",
        "    \"letters\": 26,\n",
        "    \"digits\": 10,\n",
        "    \"mnist\": 10\n",
        "}\n",
        "\n",
        "##   MAIN  PARAMS   ##\n",
        "######################\n",
        "CENTRALIZED = False  ## False if Federated\n",
        "SPLIT = \"digits\" # Choose from \"digits, balanced\"...\n",
        "MODEL = \"internet\" # Choose from \"chatgpt\", \"internet\", \"tutorial\"\n",
        "######################\n",
        "\n",
        "## OTHER GLOBAL PARAMS ##\n",
        "PROGRESS_BAR = CENTRALIZED # set to \"CENTRALIZED\" to only progress bar then\n",
        "USE_GPU = True # False for CPU\n",
        "VALIDATION_SPLIT = 0.1\n",
        "OPTIMIZER = \"adam\" # Choose from \"sgd\" and \"adam\"\n",
        "CRITERION = nn.CrossEntropyLoss()\n",
        "VISUALIZE_N = 8 # Amount of visualized images\n",
        "\n",
        "### CENTRALIZED PARAMS ###\n",
        "LR_CENTRALIZED = 0.001  # Learning rate\n",
        "MOM_CENTRALIZED = 0.9 # Momentum\n",
        "EPOCHS_CENTRALIZED = 50 # Epochs\n",
        "BATCH_SIZE_CENTRALIZED = 256\n",
        "PATIENCE = 3\n",
        "\n",
        "### FEDERATED PARAMS ###\n",
        "IMBALANCE_PERCENTAGE = 0  # set to 0 to use original dataset\n",
        "KEEP_INTACT_PERCENTAGE = 0.3\n",
        "\n",
        "LR_FEDERATED = 0.001  # Learning rate\n",
        "MOM_FEDERATED = 0.9 # Momentum ?\n",
        "EPOCHS_FEDERATED = 1 # Epochs\n",
        "BATCH_SIZE_FEDERATED = 128\n",
        "NUM_CLIENTS = 100\n",
        "FRACTION_TRAIN = 0.2 # Percentage of clients chosen to train each round\n",
        "FRACTION_VALIDATE = 0.2 # Percentage of clients chosen to validate each round\n",
        "STRATEGY = \"FedAvg\" # Choose from \"FedAvg\", \"FedAdam\", \"FedProx\"\n",
        "\n",
        "\n",
        "# ---------- DO NOT CHANGE ------------ #\n",
        "NUM_CLASSES = EMNIST_SPLITS[SPLIT]\n",
        "now = datetime.now()\n",
        "SAVE_DATE = now.strftime(\"%Y%d%m_%H%M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub4buF05zreH"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2_AiAfz1nf0"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajr_6muW7QmT"
      },
      "source": [
        "### Raw dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS9pcXiT1nf1"
      },
      "outputs": [],
      "source": [
        "def get_dataset():\n",
        "    data_path = \"./data\"\n",
        "    # get the transforms\n",
        "    emnist_train = EMNIST(root=data_path, split=SPLIT, train = True, download=True)\n",
        "    mean = emnist_train.data.float().mean() / 255\n",
        "    std = emnist_train.data.float().std() / 255\n",
        "    EMNIST_TRANSFORM = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean, std)])\n",
        "    # prepare train and test set\n",
        "    trainset = EMNIST(data_path, split=SPLIT, train=True, download=True, transform=EMNIST_TRANSFORM)\n",
        "    testset = EMNIST(data_path, split=SPLIT, train=False, download=True, transform=EMNIST_TRANSFORM)\n",
        "\n",
        "    return trainset, testset\n",
        "\n",
        "def get_testloader():\n",
        "    _, testset = get_dataset()\n",
        "    return DataLoader(testset, batch_size=BATCH_SIZE_FEDERATED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWktBjDS7J_A"
      },
      "source": [
        "### Federated Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRzIWlbY7KjP"
      },
      "outputs": [],
      "source": [
        "# Create Federated Dataset\n",
        "def get_federated_loaders():\n",
        "    trainset, testset = get_dataset()\n",
        "    global num_images\n",
        "    num_images = len(trainset) // NUM_CLIENTS\n",
        "    partition_len = [num_images] * NUM_CLIENTS\n",
        "\n",
        "    trainset_adjusted = Subset(trainset, range(NUM_CLIENTS * num_images))\n",
        "\n",
        "    print(\"Number of Images per client before imblaning:\", num_images)\n",
        "    print(\"Total images among clients:\", num_images*NUM_CLIENTS)\n",
        "\n",
        "    trainsets = random_split(trainset_adjusted, partition_len)\n",
        "\n",
        "    trainsets = imbalance_sets(trainsets)\n",
        "\n",
        "    #\n",
        "    global TRAINSETS\n",
        "    TRAINSETS = trainsets\n",
        "\n",
        "    # create dataloaders with train+val support\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for trainset_ in trainsets:\n",
        "        num_total = len(trainset_)\n",
        "        num_val = int(VALIDATION_SPLIT * num_total)\n",
        "        num_train = num_total - num_val\n",
        "\n",
        "        for_train, for_val = random_split(trainset_, [num_train, num_val])\n",
        "\n",
        "        trainloaders.append(\n",
        "            DataLoader(for_train, batch_size=BATCH_SIZE_FEDERATED, shuffle=True, num_workers=2))\n",
        "        valloaders.append(\n",
        "            DataLoader(for_val, batch_size=BATCH_SIZE_FEDERATED, shuffle=False, num_workers=2))\n",
        "\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE_FEDERATED)\n",
        "\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "def imbalance_sets(sets):\n",
        "    amount_to_remove = int(len(sets)*IMBALANCE_PERCENTAGE)\n",
        "    for i in range(amount_to_remove):\n",
        "        for set in sets:\n",
        "            random_idx = random.randint(0, len(set) - 1)\n",
        "            set.pop(random_idx)\n",
        "    return sets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1blLH-cK1nf5"
      },
      "source": [
        "## CNN Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vy7MJq71nf5"
      },
      "outputs": [],
      "source": [
        "class TutorialNet(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(TutorialNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, NUM_CLASSES)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"TutorialNet\"\n",
        "\n",
        "class InternetNet(nn.Module):\n",
        "    def __init__(self, fmaps1 = 40, fmaps2 = 160, dense = 200, dropout = 0.4):\n",
        "        super(InternetNet, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=fmaps1, kernel_size=5, stride=1, padding='same'),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=fmaps1, out_channels=fmaps2, kernel_size=5, stride=1, padding='same'),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.fcon1 = nn.Sequential(nn.Linear(49*fmaps2, dense), nn.LeakyReLU())\n",
        "        self.fcon2 = nn.Linear(dense, NUM_CLASSES)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(self.fcon1(x))\n",
        "        x = self.fcon2(x)\n",
        "        return x\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"InternetNet\"\n",
        "\n",
        "\n",
        "class ChatGPTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChatGPTNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, NUM_CLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"CHA-GPTNet\"\n",
        "\n",
        "def get_model():\n",
        "    if MODEL == \"chatgpt\":\n",
        "        return ChatGPTNet()\n",
        "    elif MODEL == \"internet\":\n",
        "        return InternetNet()\n",
        "    elif MODEL == \"tutorial\":\n",
        "        return TutorialNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7M57_yT1nf6"
      },
      "source": [
        "## Train and Test Loops\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcOvbgZk1nf6"
      },
      "outputs": [],
      "source": [
        "def train_centralized(net, optimizer, trainloader, valloader, epochs):\n",
        "    print(\"----- * * * * Training Starting * * * * -----\")\n",
        "    valid_accuracy_hist, loss_hist = [], []\n",
        "    best_accuracy = 0.0\n",
        "    best_model = None\n",
        "    no_improve_epochs = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        tqdm_trainloader = tqdm(trainloader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\")\n",
        "        for i, (images, labels) in enumerate(tqdm_trainloader):\n",
        "            if USE_GPU:\n",
        "                images, labels =  images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            outputs = net(images)\n",
        "            loss = CRITERION(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 5:\n",
        "                tqdm_trainloader.set_postfix({'loss': running_loss / len(tqdm_trainloader)})\n",
        "\n",
        "        _, running_accuracy = test(net, valloader)\n",
        "        valid_accuracy_hist.append(running_accuracy)\n",
        "        loss_hist.append(running_loss)\n",
        "        print(f\"Epoch {epoch + 1} completed. Loss: {running_loss}, Accuracy: {running_accuracy}\")\n",
        "\n",
        "        # Save the model if it has the best accuracy so far\n",
        "        if running_accuracy > best_accuracy:\n",
        "            best_accuracy = running_accuracy\n",
        "            best_model = copy.deepcopy(net)\n",
        "            no_improve_epochs = 0\n",
        "        else:\n",
        "            no_improve_epochs += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if no_improve_epochs >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    history = (valid_accuracy_hist, loss_hist)\n",
        "    print(\"----- * * * * Training Finished * * * * -----\")\n",
        "    return best_model, history\n",
        "\n",
        "\n",
        "def train_federated(net, optimizer, trainloader):\n",
        "    net.train()\n",
        "    for images, labels in trainloader:\n",
        "        if USE_GPU:\n",
        "            images, labels =  images.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        loss = CRITERION(net(images), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return net\n",
        "\n",
        "def test(net, testloader):\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            if USE_GPU:\n",
        "                images, labels =  images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += CRITERION(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MewAgQS8m1RB"
      },
      "source": [
        "## Other Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dIAe5QmCG5b"
      },
      "outputs": [],
      "source": [
        "def get_distributions():\n",
        "    local_distributions = []\n",
        "    trainset, _ = get_dataset()\n",
        "    for subset in TRAINSETS:\n",
        "        labels = trainset.targets[subset.indices]\n",
        "        unique, counts = torch.unique(labels, return_counts=True)\n",
        "        distribution = torch.zeros(len(trainset.classes), dtype=torch.long)\n",
        "        distribution[unique.long()] = counts\n",
        "        local_distributions.append(distribution.float())\n",
        "\n",
        "    global_distribution = torch.sum(torch.stack(local_distributions), dim=0).float()\n",
        "\n",
        "    return global_distribution, local_distributions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQH2p6AJm4tW"
      },
      "outputs": [],
      "source": [
        "def get_optim(model):\n",
        "    if CENTRALIZED:\n",
        "        lr = LR_CENTRALIZED\n",
        "        mom = MOM_CENTRALIZED\n",
        "    else:\n",
        "        lr = LR_FEDERATED\n",
        "        mom = MOM_FEDERATED\n",
        "    if OPTIMIZER == \"sgd\":\n",
        "        return optim.SGD(model.parameters(), lr=lr, momentum=mom)\n",
        "    elif OPTIMIZER == \"adam\":\n",
        "        return optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVsJsH-Rjssv"
      },
      "outputs": [],
      "source": [
        "# MID functions outside the model, as it is a \"global\"- Calculation for the parameters we put in\n",
        "def calculate_MID(global_distribution):\n",
        "    global_distribution, local_distributions = get_distributions()\n",
        "    N = sum(global_distribution)  # Total number of instances\n",
        "    MID = 0.0\n",
        "    for c in range(NUM_CLASSES):\n",
        "        n_c = global_distribution[c]  # Number of instances in class c\n",
        "        MID += (n_c / float(N)) * math.log(NUM_CLASSES * n_c / float(N), NUM_CLASSES)\n",
        "    return MID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyb79GgLPQt8"
      },
      "outputs": [],
      "source": [
        "# WCS now outside the eval-function (makes more sense, as the individual Client\n",
        "# is unimportant, we only need the dataset (trainloader(s)))\n",
        "def calculate_WCS(global_distribution, local_distributions):\n",
        "    # Calculate WCS\n",
        "    global_distribution = global_distribution.float()\n",
        "    local_sum = 0\n",
        "    g_norm_1 = torch.linalg.norm(global_distribution, dim=0, ord=1)\n",
        "    g_norm_2 = torch.linalg.norm(global_distribution, dim=0, ord=2)\n",
        "\n",
        "    for local_distribution in local_distributions:\n",
        "        local_distribution = local_distribution.float()\n",
        "        l_norm_1 = torch.linalg.norm(local_distribution, dim=0, ord=1)\n",
        "        l_norm_2 = torch.linalg.norm(local_distribution, dim=0, ord=2)\n",
        "        local_sum += ((l_norm_1/l_norm_2)*((global_distribution).dot(local_distribution)))\n",
        "\n",
        "    # Mathematical definition of the WCS\n",
        "    WCS = (1/(g_norm_1*g_norm_2))*local_sum\n",
        "\n",
        "    return WCS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tewM-q21nf6"
      },
      "source": [
        "## Centralized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y5GiYgAiAyW"
      },
      "source": [
        "Format for history dict:\n",
        "- model: latest model\n",
        "- accuracies_centralized\n",
        "- accuracies_federated\n",
        "- losses_centralized\n",
        "- losses_federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS9mCrGP1nf6"
      },
      "outputs": [],
      "source": [
        "def run_centralized():\n",
        "    model = get_model()\n",
        "    if USE_GPU:\n",
        "        model.to(DEVICE)\n",
        "\n",
        "    optim = get_optim(model)\n",
        "\n",
        "    trainset, testset = get_dataset()\n",
        "\n",
        "    train_size = int((1-VALIDATION_SPLIT) * len(trainset))\n",
        "    val_size = len(trainset) - train_size\n",
        "\n",
        "    trainset, valset = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=BATCH_SIZE_CENTRALIZED, shuffle=True, num_workers=2)\n",
        "    valloader = DataLoader(valset, batch_size=BATCH_SIZE_CENTRALIZED)\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE_CENTRALIZED)\n",
        "\n",
        "    trained_model, history = train_centralized(model, optim, trainloader, valloader, EPOCHS_CENTRALIZED)\n",
        "\n",
        "    return {\"model\":trained_model, \"accuracies_centralized\": history[0], \"accuracies_federated\": [],\n",
        "            \"losses_centralized\": history[1], \"losses_federated\": []}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "620-s91l8MHK"
      },
      "source": [
        "## Federated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzGcva8S8QCC"
      },
      "source": [
        "### Flower Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cC-BM2C1ngC"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, trainloader, valloader) -> None:\n",
        "        super().__init__()\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.model = get_model().to(DEVICE)\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar]):\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        optim = get_optim(self.model)\n",
        "        _ = train_federated(self.model, optim, self.trainloader)\n",
        "        return self.get_parameters({}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test(self.model, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": accuracy}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfkOWnrpBlpI"
      },
      "source": [
        "### Other Federated Functionality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgHjb7e2BrCC"
      },
      "outputs": [],
      "source": [
        "def get_evalulate_fn(testloader):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        model = get_model()\n",
        "        model.to(DEVICE)\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        loss, accuracy = test(model, testloader)\n",
        "\n",
        "\n",
        "        return loss, {\"accuracy\": accuracy, \"model\": model}\n",
        "    return evaluate_fn\n",
        "\n",
        "def generate_client_fn(trainloaders, valloaders):\n",
        "    def client_fn(cid: str):\n",
        "        return FlowerClient(\n",
        "            trainloader=trainloaders[int(cid)], valloader=valloaders[int(cid)]\n",
        "        ).to_client()\n",
        "    return client_fn\n",
        "\n",
        "def aggregate_evaluate_metrics(metrics):\n",
        "    # This function will receive a list of (num_examples, client_metric_dict) tuples\n",
        "    # Extract accuracies from client_metric_dict and weights from num_examples\n",
        "    accuracies = [client_metric_dict[\"accuracy\"] for num_examples, client_metric_dict in metrics]\n",
        "    weights = [num_examples for num_examples, client_metric_dict in metrics]\n",
        "\n",
        "    # Weighted average of accuracies\n",
        "    accuracy_aggregated = sum(a*w for a, w in zip(accuracies, weights)) / sum(weights)\n",
        "\n",
        "    # Return a dict with the aggregated metrics\n",
        "    return {\"accuracy\": accuracy_aggregated}\n",
        "\n",
        "\n",
        "def get_strategy(testloader):\n",
        "    if STRATEGY == \"FedAvg\":\n",
        "        return fl.server.strategy.FedAvg(\n",
        "            fraction_fit = FRACTION_TRAIN,\n",
        "            fraction_evaluate = FRACTION_VALIDATE,\n",
        "            min_available_clients = NUM_CLIENTS,  # total number of clients available in the experiment\n",
        "            evaluate_fn=get_evalulate_fn(testloader),  # a callback to a function that the strategy can execute to evaluate the state of the global model on a centralised dataset\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters([val.cpu().numpy() for _, val in get_model().state_dict().items()]),\n",
        "            evaluate_metrics_aggregation_fn=aggregate_evaluate_metrics,)\n",
        "    elif STRATEGY == \"FedAdam\":\n",
        "        return fl.server.strategy.FedAdam(\n",
        "            fraction_fit = FRACTION_TRAIN,\n",
        "            fraction_evaluate = FRACTION_VALIDATE,\n",
        "            min_available_clients = NUM_CLIENTS,  # total number of clients available in the experiment\n",
        "            evaluate_fn=get_evalulate_fn(testloader),  # a callback to a function that the strategy can execute to evaluate the state of the global model on a centralised dataset\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters([val.cpu().numpy() for _, val in get_model().state_dict().items()]),\n",
        "            evaluate_metrics_aggregation_fn=aggregate_evaluate_metrics,)\n",
        "    elif STRATEGY == \"FedProx\":\n",
        "        return fl.server.strategy.FedProx(\n",
        "            fraction_fit = FRACTION_TRAIN,\n",
        "            fraction_evaluate = FRACTION_VALIDATE,\n",
        "            min_available_clients = NUM_CLIENTS,  # total number of clients available in the experiment\n",
        "            evaluate_fn=get_evalulate_fn(testloader),  # a callback to a function that the strategy can execute to evaluate the state of the global model on a centralised dataset\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters([val.cpu().numpy() for _, val in get_model().state_dict().items()]),\n",
        "            evaluate_metrics_aggregation_fn=aggregate_evaluate_metrics,)\n",
        "\n",
        "def get_metrics(history):\n",
        "    # Extract the metrics from the history object\n",
        "\n",
        "    model = history.metrics_centralized['model'][-1][1]  # Get the last model\n",
        "    accuracies_centralized = [x[1] for x in history.metrics_centralized['accuracy']]\n",
        "    accuracies_federated = [history.metrics_centralized['accuracy'][0][1]] + [x[1] for x in history.metrics_distributed['accuracy']]\n",
        "    losses_centralized = [x[1] for x in history.losses_centralized]\n",
        "    losses_federated = [history.losses_centralized[0][1]] + [x[1] * NUM_CLIENTS for x in history.losses_distributed]\n",
        "\n",
        "    # Return the metrics in the desired format\n",
        "    return {\n",
        "        \"model\": model,\n",
        "        \"accuracies_centralized\": accuracies_centralized,\n",
        "        \"accuracies_federated\": accuracies_federated,\n",
        "        \"losses_centralized\": losses_centralized,\n",
        "        \"losses_federated\": losses_federated\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZXhFk1WC7R_"
      },
      "source": [
        "### Run Federated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf5kopyUC-tf"
      },
      "outputs": [],
      "source": [
        "def run_federated():\n",
        "    trainloaders, valloaders, testloader = get_federated_loaders()\n",
        "    client_fn_callback = generate_client_fn(trainloaders, valloaders)\n",
        "    strategy = get_strategy(testloader)\n",
        "\n",
        "    client_resources = None\n",
        "    if DEVICE.type == \"cuda\":\n",
        "        client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn_callback,\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=EPOCHS_FEDERATED),\n",
        "        strategy=strategy,\n",
        "        client_resources=client_resources)\n",
        "    print(history)\n",
        "    return get_metrics(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWl9JIeWmgRO"
      },
      "source": [
        "## Plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWF0c7I3mlRn"
      },
      "outputs": [],
      "source": [
        "def visualise_n_random_examples(testset, model):\n",
        "    if VISUALIZE_N == 0:\n",
        "        return\n",
        "    # take n examples at random\n",
        "    idx = list(range(len(testset)))\n",
        "    random.shuffle(idx)\n",
        "    idx = idx[:VISUALIZE_N]\n",
        "    # construct canvas\n",
        "    num_cols = 8\n",
        "    num_rows = int(np.ceil(len(idx) / num_cols))\n",
        "    fig, axs = plt.subplots(figsize=(16, 6), nrows=num_rows, ncols=num_cols)\n",
        "\n",
        "    # display images on canvas\n",
        "    for c_i, i in enumerate(idx):\n",
        "        image, label = testset[i]\n",
        "        image_squeezed = np.squeeze(image)\n",
        "        image_input = image.unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(image_input)\n",
        "            prediction = output.argmax(dim=1).item()\n",
        "            confidence = F.softmax(output, dim=1)[0][prediction].item()\n",
        "\n",
        "        correct = (label == prediction)\n",
        "        color = 'green' if correct else 'red'\n",
        "\n",
        "        axs.flat[c_i].imshow(image_squeezed, cmap=\"gray\")\n",
        "        axs.flat[c_i].set_title(f'True/Pred: [{label}/{prediction}] ({confidence*100:.0f}%)', color=color)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def save_params(test_results):\n",
        "    if not CENTRALIZED:\n",
        "        global_d, local_d = get_distributions()\n",
        "        MID_result = calculate_MID(global_d)\n",
        "        WCS_result = calculate_WCS(global_d,local_d)\n",
        "        print(f\"MID: {MID_result}, WCS: {WCS_result}\")\n",
        "        print(\"Images per client: \" + str(num_images))\n",
        "    with open(f'/content/drive/My Drive/LAMA_ItW/{SAVE_DATE}_Params_{MODEL}{SPLIT}NC{NUM_CLIENTS}BS{BATCH_SIZE_FEDERATED}EP{EPOCHS_FEDERATED}.txt', 'w') as f:\n",
        "        text_1 = f'''\n",
        "        Filename: {SAVE_DATE}_Params_{MODEL}{SPLIT}NC{NUM_CLIENTS}BS{BATCH_SIZE_FEDERATED}EP{EPOCHS_FEDERATED}\n",
        "        ## Test results ##\n",
        "        ACCURACY = {test_results[1]}\n",
        "        LOSS = {test_results[0]}\n",
        "\n",
        "        ##  MAIN  PARAMS ##\n",
        "        CENTRALIZED = {CENTRALIZED} ## False if Federated\n",
        "        SPLIT = {SPLIT}\n",
        "        MODEL = {MODEL}\n",
        "\n",
        "        ## OTHER GLOBAL PARAMS ##\n",
        "        VALIDATION_SPLIT = {VALIDATION_SPLIT}\n",
        "        OPTIMIZER = {OPTIMIZER}\n",
        "        '''\n",
        "        if CENTRALIZED:\n",
        "            text_2 = f'''\n",
        "        ### CENTRALIZED PARAMS ###\n",
        "        LR_CENTRALIZED = {LR_CENTRALIZED}  # Learning rate\n",
        "        MOM_CENTRALIZED = {MOM_CENTRALIZED} # Momentum\n",
        "        EPOCHS_CENTRALIZED = {EPOCHS_CENTRALIZED} # Epochs\n",
        "        BATCH_SIZE_CENTRALIZED = {BATCH_SIZE_CENTRALIZED}\n",
        "            '''\n",
        "        else:\n",
        "            text_2 = f'''\n",
        "        ## MID & WCS results ##\n",
        "        MID = {MID_result}\n",
        "        WCS = {WCS_result}\n",
        "        ### FEDERATED PARAMS ###\n",
        "        LR_FEDERATED = {LR_FEDERATED}  # Learning rate\n",
        "        MOM_FEDERATED = {MOM_FEDERATED} # Momentum\n",
        "        EPOCHS_FEDERATED = {EPOCHS_FEDERATED} # Epochs\n",
        "        BATCH_SIZE_FEDERATED = {BATCH_SIZE_FEDERATED}\n",
        "        NUM_CLIENTS = {NUM_CLIENTS}\n",
        "        IMG_PER_CLIENT = {num_images}\n",
        "        FRACTION_TRAIN = {FRACTION_TRAIN}\n",
        "        FRACTION_VALIDATE = {FRACTION_VALIDATE}\n",
        "            '''\n",
        "        f.write(text_1)\n",
        "        f.write(text_2)\n",
        "        f.close()\n",
        "\n",
        "def save_params_excel(test_results, acc_hist):\n",
        "    if not CENTRALIZED:\n",
        "        global_d, local_d = get_distributions()\n",
        "        MID_result = calculate_MID(global_d).item()\n",
        "        WCS_result = calculate_WCS(global_d,local_d).item()\n",
        "        print(f\"MID: {MID_result}, WCS: {WCS_result}\")\n",
        "        print(\"Images per client: \" + str(num_images))\n",
        "    # put results into an dict\n",
        "    if CENTRALIZED:\n",
        "        res = {'name': f'{SAVE_DATE}_Params_{MODEL}{SPLIT}NC{NUM_CLIENTS}BS{BATCH_SIZE_FEDERATED}EP{EPOCHS_FEDERATED}',\n",
        "            'centralized': CENTRALIZED, 'accuracy': 'placeholder1',\n",
        "            'loss': 'placeholder0', 'split': SPLIT, 'model': MODEL,\n",
        "            'val_split': VALIDATION_SPLIT, 'optimizer': OPTIMIZER,\n",
        "            'learning_rate': LR_CENTRALIZED, 'momentum': MOM_CENTRALIZED,\n",
        "            'epochs': EPOCHS_CENTRALIZED, 'batchsize': BATCH_SIZE_CENTRALIZED,\n",
        "            'mid': MID_result, 'wcs': WCS_result,\n",
        "            'num_clients': 0, 'img_per_client': 0,\n",
        "            'fraction_train': 0, 'fraction_val': 0,\n",
        "            'acc_hist': str(acc_hist)\n",
        "            }\n",
        "    else:\n",
        "        res = {'name': f'{SAVE_DATE}_Params_{MODEL}{SPLIT}NC{NUM_CLIENTS}BS{BATCH_SIZE_FEDERATED}EP{EPOCHS_FEDERATED}',\n",
        "                'centralized': CENTRALIZED, 'accuracy': 'placeholder1',\n",
        "                'loss': 'placeholder0', 'split': SPLIT, 'model': MODEL,\n",
        "                'val_split': VALIDATION_SPLIT, 'optimizer': OPTIMIZER,\n",
        "                'learning_rate': LR_FEDERATED, 'momentum': MOM_FEDERATED,\n",
        "                'epochs': EPOCHS_FEDERATED, 'batchsize': BATCH_SIZE_FEDERATED,\n",
        "                'mid': MID_result, 'wcs': WCS_result,\n",
        "                'num_clients': NUM_CLIENTS, 'img_per_client': num_images,\n",
        "                'fraction_train': FRACTION_TRAIN, 'fraction_val': FRACTION_VALIDATE,\n",
        "                'acc_hist': str(acc_hist)\n",
        "                }\n",
        "\n",
        "    # Load the workbook\n",
        "    wb = load_workbook(filename='/content/drive/My Drive/LAMA_ItW/Results.xlsx')\n",
        "    # Select sheet & append data\n",
        "    data_to_append = list(res.values())\n",
        "    print(data_to_append)\n",
        "    sheet = wb['results']\n",
        "    sheet.append(data_to_append)\n",
        "    wb.save(filename='/content/drive/My Drive/LAMA_ItW/Results.xlsx')\n",
        "\n",
        "def plot_metrics(history):\n",
        "    testloader = get_testloader()\n",
        "    _, testset = get_dataset()\n",
        "    model = history[\"model\"]\n",
        "\n",
        "    test_results = test(model, testloader)\n",
        "    print(f'Final accuracy: {test_results[1]*100:.1f}')\n",
        "\n",
        "    save_params(test_results)\n",
        "    save_params_excel(test_results, history['accuracies_centralized'])\n",
        "\n",
        "    # Check if federated metrics are not empty\n",
        "    if history['accuracies_federated'] and history['losses_federated']:\n",
        "        # Plot federated accuracies\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(history['accuracies_federated'], label='Federated Accuracy')\n",
        "        plt.plot(history['accuracies_centralized'], label='Centralized Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.yticks([i/10 for i in range(11)])  # Add ticks every 0.1\n",
        "        plt.legend()\n",
        "        plt.savefig(f'/content/drive/My Drive/LAMA_ItW/{SAVE_DATE}_Fed_Acc_{MODEL}{SPLIT}NC{NUM_CLIENTS}BS{BATCH_SIZE_FEDERATED}EP{EPOCHS_FEDERATED}.png')\n",
        "        plt.show()\n",
        "\n",
        "        # Plot federated losses\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(history['losses_federated'], label='Federated Loss')\n",
        "        plt.plot(history['losses_centralized'], label='Centralized Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'/content/drive/My Drive/LAMA_ItW/{SAVE_DATE}_Fed_Loss_{MODEL}{SPLIT}NC{NUM_CLIENTS}BS{BATCH_SIZE_FEDERATED}EP{EPOCHS_FEDERATED}.png')\n",
        "        plt.show()\n",
        "    else:\n",
        "        # Plot centralized accuracies and losses only\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(history['accuracies_centralized'], label='Centralized Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.yticks([i/10 for i in range(11)])  # Add ticks every 0.1\n",
        "        plt.legend()\n",
        "        plt.savefig(f'/content/drive/My Drive/LAMA_ItW/{SAVE_DATE}_Cent_Acc_{MODEL}{SPLIT}NC{NUM_CLIENTS}BS{BATCH_SIZE_FEDERATED}EP{EPOCHS_FEDERATED}.png')\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(history['losses_centralized'], label='Centralized Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'/content/drive/My Drive/LAMA_ItW/{SAVE_DATE}_Cent_Loss_{MODEL}{SPLIT}NC{NUM_CLIENTS}BS{BATCH_SIZE_FEDERATED}EP{EPOCHS_FEDERATED}.png')\n",
        "        plt.show()\n",
        "\n",
        "    # Print the final accuracy\n",
        "\n",
        "    # Make a Save of the model Params as a textfile\n",
        "\n",
        "    visualise_n_random_examples(testset, model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_fhdPgk1ngD"
      },
      "source": [
        "# Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZjLpcQE1ngD"
      },
      "outputs": [],
      "source": [
        "if CENTRALIZED:\n",
        "    history = run_centralized()\n",
        "else:\n",
        "    history = run_federated()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxf1c1Gy1ngE"
      },
      "source": [
        "# Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_gbO_IWmZmL"
      },
      "outputs": [],
      "source": [
        "plot_metrics(history)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ajr_6muW7QmT",
        "TWktBjDS7J_A",
        "1blLH-cK1nf5",
        "w7M57_yT1nf6",
        "MewAgQS8m1RB",
        "620-s91l8MHK",
        "zfkOWnrpBlpI",
        "dZXhFk1WC7R_"
      ],
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}